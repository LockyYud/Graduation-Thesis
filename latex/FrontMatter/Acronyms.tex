\newacronym{acl}{ACL}{Association for Computational Linguistics}
\newacronym{mediqa}{MEDIQA}{Medical Question-Answering}
\newacronym{bart}{BART}{Bidirectional Auto Regressive Transformer}
\newacronym{mmr}{MMR}{Maximal Marginal Relevance}
\newacronym{pegasus}{PEGASUS}{Pre-training with Extracted Gap-sentences for Abstractive Summarization}
\newacronym{bert}{BERT}{Bidirectional Encoder Representations from Transformers}
\newacronym{gpt}{GPT}{Generative Pre-training Transformer}
\newacronym{rouge}{ROUGE}{Recall-Oriented Understudy for Gisting Evaluation}
\newacronym{lcs}{LCS}{Longest Common Subsequence}
\newacronym{mas}{MAS}{Multi-Answer Summarization}
\newacronym{qa}{QA}{Question-Answering}
\newacronym{ner}{NER}{Named-Entities Recognition}
\newacronym{pos}{POS}{Part-Of-Speech}
\newacronym{llm}{LLM}{Large Language Model}
\newacronym{lstm}{LSTM}{Long Short-Term Memory}
\newacronym{gb}{GB}{Gradient Boosting}
\newacronym{pca}{PCA}{Principle Component Analysis}
\newacronym{mae}{MAE}{Mean Absolute Error}
\newacronym{mse}{MSE}{Mean Square Error}
\newacronym{mlp}{MLP}{Multi-Layer Perception}
\newacronym{nlp}{NLP}{Natural Language Processing - Xử lý ngôn ngữ tự nhiên}
\newacronym{roberta}{RoBERTa}{Robustly optimized BERT pre-training approach}
\glsaddall